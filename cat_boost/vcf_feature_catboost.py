#!/usr/bin/env python3
"""
Variant ensemble ML pipeline with TRUE ground truth.

- Merge multiple VCFs into a single variant table
- Annotate with GFF3 / BED (RepeatMasker, Liftoff, low complexity, Flagger)
- Add Merqury QV and BUSCO status as FEATURES
- Build TRUE_VARIANT label from truth VCF
- Train CatBoostClassifier (binary classification)
- Output filtered VCF with ML probability

Author: autogenerated
"""

import argparse
from pathlib import Path
import pandas as pd
import numpy as np
from intervaltree import IntervalTree
from cyvcf2 import VCF, Writer
from catboost import CatBoostClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score

# ------------------------------------------------------------
# Utilities
# ------------------------------------------------------------

def load_vcf_as_df(vcf_path, prefix):
    records = []
    vcf = VCF(str(vcf_path))
    for v in vcf:
        info = dict(v.INFO)
        row = {
            "CHROM": v.CHROM,
            "POS": v.POS,
            "END": v.end,
            "REF": v.REF,
            "ALT": str(v.ALT[0]) if v.ALT else None,
            "SVTYPE": info.get("SVTYPE", "SNV"),
            "SVLEN": info.get("SVLEN", 0),
            f"{prefix}_present": 1,
        }
        
        for k, val in info.items():
            row[f"{prefix}_INFO_{k}"] = val
        records.append(row)
    return pd.DataFrame(records)


def outer_merge_vcfs(vcf_paths):
    dfs = []
    for p in vcf_paths:
        name = Path(p).stem
        dfs.append(load_vcf_as_df(p, name))
    df = dfs[0]
    for other in dfs[1:]:
        df = df.merge(
            other,
            on=["CHROM", "POS", "END", "REF", "ALT", "SVTYPE", "SVLEN"],
            how="outer",
        )
    df.fillna(0, inplace=True)
    return df

def normalize_info_value(key, value):
    """
    Приводит INFO значения к scalar (int/float/str)
    """
    if value is None:
        return None

    # Sniffles COVERAGE: tuple / list
    if key.upper() == "COVERAGE":
        if isinstance(value, (list, tuple)) and len(value) > 0:
            return float(sum(value)) / len(value)
        try:
            return float(value)
        except Exception:
            return None

    # SVLEN может быть списком
    if key.upper() == "SVLEN":
        if isinstance(value, (list, tuple)):
            return abs(float(value[0]))
        return abs(float(value))

    # Generic list/tuple → mean
    if isinstance(value, (list, tuple)):
        try:
            return float(sum(value)) / len(value)
        except Exception:
            return str(value)

    # Scalar
    return value


# ------------------------------------------------------------
# Annotation loaders
# ------------------------------------------------------------

def load_bed(path, value_col=None):
    trees = {}
    with open(path) as f:
        for line in f:
            if line.startswith("#") or not line.strip():
                continue
            parts = line.strip().split("\t")
            if len(parts) < 3:
                continue
            chrom, start, end = parts[0], int(parts[1]), int(parts[2])
            val = parts[value_col] if value_col is not None and len(parts) > value_col else 1
            trees.setdefault(chrom, IntervalTree()).addi(start, end, val)
    return trees


def load_gff3(path, attr_key=None, col_idx=None):
    trees = {}
    with open(path) as f:
        for line in f:
            if line.startswith("#"):
                continue
            parts = line.strip().split("	")
            chrom, feature = parts[0], parts[2]
            start, end = int(parts[3]), int(parts[4])
            # Guard against zero-length / invalid intervals (GFF3 allows start == end)
            if start >= end:
                continue
            value = feature
            if attr_key:
                attrs = dict(
                    x.split("=") for x in parts[8].split(";") if "=" in x
                )
                value = attrs.get(attr_key, None)
            if col_idx is not None:
                value = parts[col_idx]
            trees.setdefault(chrom, IntervalTree()).addi(start, end, value)
    return trees


# ------------------------------------------------------------
# Annotation application
# ------------------------------------------------------------

def annotate_interval(df, trees, colname):
    values = []
    for _, r in df.iterrows():
        hits = trees.get(r.CHROM, IntervalTree()).overlap(r.POS, r.END)
        values.append(next(iter(hits)).data if hits else None)
    df[colname] = values


# ------------------------------------------------------------
# Truth VCF matching
# ------------------------------------------------------------

def load_truth_variants(truth_vcf):
    truth = set()
    vcf = VCF(truth_vcf)
    for v in vcf:
        key = (v.CHROM, v.POS, v.end, v.REF, str(v.ALT[0]) if v.ALT else None)
        truth.add(key)
    return truth


# ------------------------------------------------------------
# Main
# ------------------------------------------------------------

def main(args):
    print("[1] Loading and merging VCFs")
    df = outer_merge_vcfs(args.vcfs)
    print(f"Merged variants: {len(df):,}")

    print("[2] Loading annotations")
    repeat = load_gff3(args.repeat_gff, attr_key="Target")
    liftoff = load_gff3(args.liftoff_gff)
    low_complex = load_bed(args.low_complex)
    flagger = load_bed(args.flagger, value_col=3)

    print("[3] Annotating variants")
    annotate_interval(df, repeat, "repeat_target")
    annotate_interval(df, liftoff, "liftoff_feature")
    annotate_interval(df, low_complex, "low_complexity")
    annotate_interval(df, flagger, "flagger_state")

    # print("[4] Adding Merqury QV")
    # merq = pd.read_csv(args.merqury, sep="\t", header=None,
    #                    names=["CHROM", "START", "END", "QV"])
    # merq_trees = {}
    # for _, r in merq.iterrows():
    #     merq_trees.setdefault(r.CHROM, IntervalTree()).addi(r.START, r.END, r.QV)

    # annotate_interval(df, merq_trees, "merqury_qv")

    # print("[5] Adding BUSCO")
    # busco = pd.read_csv(args.busco, sep="\t")
    # busco_trees = {}
    # for _, r in busco.iterrows():
    #     busco_trees.setdefault(r.chrom, IntervalTree()).addi(r.start, r.end, r.status)

    # annotate_interval(df, busco_trees, "busco_status")

    print("[6] Building ground truth labels")
    print("Saving feature table to TSV for inspection")
    df.to_csv(args.out_table, sep="	", index=False)
    truth = load_truth_variants(args.truth_vcf)
    df["TRUE_VARIANT"] = df.apply(
        lambda r: int((r.CHROM, r.POS, r.END, r.REF, r.ALT) in truth), axis=1
    )

    print("[7] Training CatBoost")
    y = df.TRUE_VARIANT
    X = df.drop(columns=["TRUE_VARIANT"])

    cat_cols = X.select_dtypes(include=["object"]).columns.tolist()

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, stratify=y, random_state=42
    )

    model = CatBoostClassifier(
        iterations=500,
        depth=8,
        learning_rate=0.05,
        loss_function="Logloss",
        eval_metric="AUC",
        verbose=100
    )

    model.fit(
        X_train,
        y_train,
        cat_features=cat_cols,
        eval_set=(X_test, y_test),
    )

    preds = model.predict_proba(X_test)[:, 1]
    print("AUC:", roc_auc_score(y_test, preds))

    print("[8] Writing filtered VCF")
    base_vcf = VCF(args.vcfs[0])
    base_vcf.add_info_to_header({
        "ID": "ML_PROB",
        "Description": "CatBoost probability TRUE_VARIANT",
        "Type": "Float",
        "Number": "1",
    })
    writer = Writer(args.out_vcf, base_vcf)

    prob_map = {
        (r.CHROM, r.POS, r.END, r.REF, r.ALT): model.predict_proba(X.loc[[i]])[0][1]
        for i, r in df.iterrows()
    }

    for v in base_vcf:
        key = (v.CHROM, v.POS, v.end, v.REF, str(v.ALT[0]) if v.ALT else None)
        if key in prob_map and prob_map[key] >= args.threshold:
            v.INFO["ML_PROB"] = round(prob_map[key], 4)
            writer.write_record(v)

    writer.close()
    print("Done")


if __name__ == "__main__": 
    p = argparse.ArgumentParser()
    p.add_argument("--vcfs", nargs="+", required=True)
    p.add_argument("--truth_vcf", required=True)
    p.add_argument("--repeat_gff", required=True)
    p.add_argument("--liftoff_gff", required=True)
    p.add_argument("--low_complex", required=True)
    p.add_argument("--flagger", required=True)
    # p.add_argument("--merqury", required=True)
    # p.add_argument("--busco", required=True)
    p.add_argument("--out_vcf", required=True)
    p.add_argument("--out_table", default="variant_features.tsv")
    p.add_argument("--threshold", type=float, default=0.9)
    args = p.parse_args()
    main(args)
